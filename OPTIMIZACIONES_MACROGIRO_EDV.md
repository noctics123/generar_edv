# Optimizaciones Aplicadas a HM_MATRIZTRANSACCIONPOSMACROGIRO_EDV.py

## Resumen Ejecutivo

Script optimizado para ejecutarse en **cluster medium** de EDV, reduciendo significativamente el tiempo de ejecuci√≥n comparado con la versi√≥n original que tarda m√°s de 4 horas en un cluster extralarge con memory optimization en producci√≥n.

## Optimizaciones Implementadas

### 1. Configuraci√≥n de Spark Optimizada

#### Cambios Realizados:
```python
# ANTES
spark.conf.set("spark.sql.shuffle.partitions", "1000")
spark.conf.set("spark.databricks.io.cache.enabled", False)

# DESPU√âS
spark.conf.set("spark.sql.shuffle.partitions", "400")  # Reducido para cluster medium
spark.conf.set("spark.databricks.io.cache.enabled", True)  # Habilitado para mejor performance
```

#### Nuevas Configuraciones Agregadas:
- **AQE (Adaptive Query Execution)**: Optimizaci√≥n din√°mica de queries
  - `spark.sql.adaptive.enabled = True`
  - `spark.sql.adaptive.coalescePartitions.enabled = True`
  - `spark.sql.adaptive.skewJoin.enabled = True`

- **Optimizaciones de Join**:
  - `spark.sql.autoBroadcastJoinThreshold = 50MB`: Broadcast autom√°tico para tablas peque√±as

- **Optimizaciones Delta**:
  - `spark.databricks.delta.optimizeWrite.enabled = True`: Escritura optimizada
  - `spark.databricks.delta.autoCompact.enabled = True`: Auto-compactaci√≥n de archivos peque√±os

- **Optimizaci√≥n de Lectura**:
  - `spark.sql.files.maxPartitionBytes = 256MB`: Tama√±o √≥ptimo de partici√≥n

#### Impacto Esperado:
- ‚ö° **30-40% reducci√≥n** en shuffles gracias a AQE
- üìâ **Menor uso de memoria** con particiones ajustadas a cluster medium
- üöÄ **Joins m√°s r√°pidos** con broadcast autom√°tico y skew handling

---

### 2. Cache Estrat√©gico

#### DataFrames Cacheados:
```python
# dfClienteCuc - usado en m√∫ltiples joins
dfClienteCuc = spark.table(...).cache()

# dfClienteCic - usado en joins con filtrado de mes
dfClienteCic = spark.sql(...).cache()
```

#### Impacto Esperado:
- ‚ö° **50-70% m√°s r√°pido** en joins repetidos
- üíæ Evita re-computaci√≥n de DataFrames intermedios
- üîÑ Mejor uso de memoria del cluster

---

### 3. Broadcast Joins Inteligentes

#### Implementaci√≥n:
```python
# Join con broadcast condicional basado en tama√±o de tabla
dfInfo12MesesStep1Cic = dfInfo12MesesStep0.join(
    F.broadcast(dfClienteCic.drop('CODMES')) if dfClienteCic.count() < 10000000
    else dfClienteCic.drop('CODMES'),
    on='CODINTERNOCOMPUTACIONAL',
    how='left'
)
```

#### Impacto Esperado:
- ‚ö° **60-80% m√°s r√°pido** en joins con tablas peque√±as (<10M registros)
- üìâ **Eliminaci√≥n de shuffles** en joins broadcasted
- üéØ Broadcast solo cuando es beneficioso (tabla peque√±a)

---

### 4. Eliminaci√≥n de Operaciones Costosas

#### Cambio Cr√≠tico - Coalesce en Loop:
```python
# ANTES (‚ùå MAL - coalesce en cada iteraci√≥n del loop)
for colName in colsToExpandCantidad2daT:
    dfMatrizVarTransaccionPosMacrogiro = dfMatrizVarTransaccionPosMacrogiro.coalesce(160)
    # ... transformaciones ...

# DESPU√âS (‚úÖ BIEN - coalesce una sola vez)
for colName in colsToExpandCantidad2daT:
    # dfMatrizVarTransaccionPosMacrogiro = dfMatrizVarTransaccionPosMacrogiro.coalesce(160)  # Comentado
    # ... transformaciones ...

# Coalesce estrat√©gico antes de escritura
dfMatrizVarTransaccionPosMacrogiro = dfMatrizVarTransaccionPosMacrogiro.coalesce(160)
```

#### Impacto Esperado:
- ‚ö° **CR√çTICO**: Evita m√∫ltiples shuffles costosos en el loop
- üöÄ **70-90% m√°s r√°pido** en la secci√≥n de post-agregaci√≥n
- üíæ Menor presi√≥n de memoria

---

### 5. DataFrame API vs SQL Vistas Temporales

#### Optimizaci√≥n:
```python
# ANTES - con vistas temporales SQL
dfInfo12MesesStep1Cic.createOrReplaceTempView('temp1_cic')
dfInfo12MesesStep1Cic = spark.sql("SELECT ... FROM temp1_cic")

# DESPU√âS - DataFrame API directo
dfInfo12MesesStep1Cic = dfInfo12MesesStep1Cic \
    .withColumnRenamed("CODUNICOCLI_LAST", "CODUNICOCLI_LAST_CIC") \
    .withColumn("CODUNICOCLI_LAST",
                F.when(F.trim(F.col("CODINTERNOCOMPUTACIONAL")) != ".", ...)
                .otherwise(...))
```

#### Impacto Esperado:
- ‚ö° **10-20% m√°s r√°pido** sin overhead de vistas temporales
- üéØ Mejor optimizaci√≥n del catalyst optimizer
- üìä Menos operaciones intermedias

---

### 6. Optimizaci√≥n de Escritura

#### Mejoras en write_temp_table:
```python
# ANTES
def write_temp_table(df, tmp_table_name, ruta_salida):
    df.write.format("delta").mode("overwrite").partitionBy("CODMES").saveAsTable(...)

# DESPU√âS
def write_temp_table(df, tmp_table_name, ruta_salida):
    df.write \
        .format("delta") \
        .option("compression", "snappy") \
        .option("partitionOverwriteMode", "dynamic") \
        .mode("overwrite") \
        .partitionBy("CODMES") \
        .saveAsTable(...)
```

#### Impacto Esperado:
- üíæ **Mejor compresi√≥n** de datos temporales
- üéØ **Dynamic partition overwrite** m√°s eficiente
- üìâ Menor I/O en disco

---

### 7. Liberaci√≥n de Memoria Mejorada

#### Implementaci√≥n:
```python
# Unpersist inmediato despu√©s de uso + liberaci√≥n de cache
dfClienteCic.unpersist()
dfClienteCuc.unpersist()
del dfClienteCic
del dfClienteCuc
```

#### Impacto Esperado:
- üíæ **Mejor gesti√≥n de memoria** del cluster
- üîÑ Evita OOM (Out of Memory) errors
- ‚ö° M√°s memoria disponible para operaciones siguientes

---

## Estimaci√≥n de Mejora Total

### Comparativa de Tiempos Esperados:

| Ambiente | Cluster | Tiempo Actual | Tiempo Esperado | Mejora |
|----------|---------|---------------|-----------------|--------|
| **Producci√≥n** | Extralarge (mem opt) | **~4 horas** | N/A | Baseline |
| **EDV (SIN optimizaci√≥n)** | Medium | **~6-8 horas** | Proyectado | -50% a -100% |
| **EDV (CON optimizaci√≥n)** | Medium | N/A | **~2-3 horas** | **50-60% m√°s r√°pido** |

### Factores de Mejora por Componente:

1. **AQE + Shuffle Partitions**: 30-40% reducci√≥n
2. **Cache Estrat√©gico**: 20-30% en joins
3. **Broadcast Joins**: 20-30% en joins peque√±os
4. **Eliminaci√≥n Coalesce en Loop**: **70-90%** en post-agregaci√≥n ‚≠ê CR√çTICO
5. **DataFrame API vs SQL**: 10-20%
6. **Escritura Optimizada**: 10-15%

**Mejora Acumulativa Estimada: 50-60%**

---

## Recomendaciones Adicionales para Ejecuci√≥n

### 1. Configuraci√≥n del Cluster Medium en EDV

#### Especificaciones Recomendadas:
```yaml
Cluster Mode: Standard
Node Type: Standard_D8s_v3 (8 cores, 32GB RAM) o similar
Workers: 4-6 workers (ajustar seg√∫n volumen de datos)
Autoscaling: Habilitado (min: 3, max: 8)
Databricks Runtime: 13.3 LTS o superior (mejor AQE)
```

### 2. Monitoreo Durante Ejecuci√≥n

#### M√©tricas Clave a Observar:
```python
# Agregar al inicio del script para monitoreo
import time
start_time = time.time()

# Agregar despu√©s de cada secci√≥n cr√≠tica
print(f"‚è±Ô∏è Tiempo transcurrido: {(time.time() - start_time)/60:.2f} minutos")
```

#### Usar Spark UI para:
- ‚úÖ Verificar que broadcast joins se est√°n aplicando
- ‚úÖ Confirmar que AQE est√° optimizando queries
- ‚úÖ Monitorear uso de memoria y cache hits
- ‚úÖ Identificar stages con data skew

### 3. Ajustes Finos Post-Ejecuci√≥n

#### Si el job es muy lento:
```python
# Incrementar particiones si hay mucho data skew
spark.conf.set("spark.sql.shuffle.partitions", "500")

# Incrementar threshold de broadcast si hay memoria suficiente
spark.conf.set("spark.sql.autoBroadcastJoinThreshold", "100MB")
```

#### Si hay errores de memoria:
```python
# Reducir particiones para menor overhead
spark.conf.set("spark.sql.shuffle.partitions", "300")

# Reducir threshold de broadcast
spark.conf.set("spark.sql.autoBroadcastJoinThreshold", "30MB")

# Reducir coalesce final
dfMatrizVarTransaccionPosMacrogiro = dfMatrizVarTransaccionPosMacrogiro.coalesce(100)
```

### 4. Optimizaciones Futuras Opcionales

#### Para Mayor Velocidad (requiere m√°s memoria):
```python
# Aumentar buffer de memoria para joins
spark.conf.set("spark.sql.join.preferSortMergeJoin", "false")

# Z-Order optimization en tabla final (ejecutar una vez)
spark.sql("OPTIMIZE {tabla_destino} ZORDER BY (codunicocli, codmesanalisis)")

# Vacuum peri√≥dico de tablas temporales
spark.sql("VACUUM {tabla_temp} RETAIN 0 HOURS")
```

---

## Validaci√≥n de Resultados

### ‚úÖ Checklist Post-Ejecuci√≥n:

1. **Integridad de Datos**:
   - [ ] Mismo n√∫mero de registros que versi√≥n original
   - [ ] Mismas columnas y tipos de datos
   - [ ] Validaci√≥n de checksums en columnas clave

2. **Performance**:
   - [ ] Tiempo de ejecuci√≥n < 3 horas en cluster medium
   - [ ] Sin errores de memoria (OOM)
   - [ ] Uso de cluster < 80% de capacidad m√°xima

3. **Calidad de Salida**:
   - [ ] Tablas temporales correctamente limpiadas (TRUNCATE + VACUUM)
   - [ ] Tabla final particionada correctamente por CODMES
   - [ ] Compresi√≥n snappy aplicada

### üîç Query de Validaci√≥n:
```sql
-- Comparar conteos entre versi√≥n original y optimizada
SELECT
    COUNT(*) as total_registros,
    COUNT(DISTINCT codunicocli) as clientes_unicos,
    MIN(codmesanalisis) as mes_min,
    MAX(codmesanalisis) as mes_max,
    SUM(pos_mto_trx_ig01_u1m) as suma_validacion
FROM {tabla_destino}
WHERE codmes = {mes_proceso};
```

---

## Troubleshooting

### Problema: Job muy lento en etapa de JOIN
**Soluci√≥n**:
- Verificar que cache est√° funcionando: `dfClienteCuc.is_cached`
- Revisar Spark UI para confirmar broadcast join
- Aumentar workers del cluster si hay capacidad

### Problema: OutOfMemoryError
**Soluci√≥n**:
- Reducir `spark.sql.shuffle.partitions` a 300
- Reducir `autoBroadcastJoinThreshold` a 30MB
- Asegurar que unpersist() se est√° llamando correctamente
- Considerar aumentar RAM de workers

### Problema: Archivos peque√±os en tabla Delta
**Soluci√≥n**:
- Verificar que `autoCompact` est√° habilitado
- Ejecutar `OPTIMIZE {tabla}` manualmente
- Ajustar coalesce de 160 a un n√∫mero menor (ej: 100)

---

## Conclusi√≥n

Las optimizaciones aplicadas transforman el script para ejecutarse eficientemente en un **cluster medium** de EDV, con una **mejora esperada del 50-60%** en tiempo de ejecuci√≥n comparado con el baseline no optimizado.

**Tiempo objetivo en EDV Medium: 2-3 horas** (vs 4+ horas en Prod Extralarge)

La clave del √©xito est√° en:
1. ‚≠ê **Eliminaci√≥n de coalesce en loop** (mejora cr√≠tica)
2. üéØ **AQE habilitado** para optimizaci√≥n din√°mica
3. üíæ **Cache estrat√©gico** en DataFrames reutilizados
4. üöÄ **Broadcast joins** autom√°ticos

---

**Fecha de optimizaci√≥n**: 30/09/2025
**Optimizado por**: CLAUDE CODE
**Versi√≥n**: 3.1
