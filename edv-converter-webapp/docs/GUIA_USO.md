# üìö Gu√≠a de Uso - EDV Converter

## üéØ Introducci√≥n

EDV Converter es una aplicaci√≥n web que automatiza la conversi√≥n de scripts PySpark del ambiente DDV (Desarrollo) al ambiente EDV (Exploraci√≥n/Producci√≥n) para BCP Analytics.

## üöÄ Inicio R√°pido

### Opci√≥n 1: Ejecutar Localmente

1. **Clonar el repositorio:**
```bash
git clone https://github.com/noctics123/generar_edv.git
cd generar_edv/edv-converter-webapp
```

2. **Instalar dependencias (opcional):**
```bash
npm install
```

3. **Iniciar servidor local:**
```bash
npm start
```

4. **Abrir en navegador:**
```
http://localhost:8080
```

### Opci√≥n 2: Usar Versi√≥n Online

Visita: `https://noctics123.github.io/generar_edv/`

## üìñ C√≥mo Usar

### Paso 1: Cargar Script DDV

Tienes 3 opciones para cargar tu script:

#### A. Cargar Archivo
1. Haz clic en "Cargar archivo .py"
2. Selecciona tu script DDV
3. El archivo se cargar√° autom√°ticamente en el editor

#### B. Pegar C√≥digo
1. Copia tu script DDV completo
2. Pega en el editor de texto
3. El contador de l√≠neas se actualizar√° autom√°ticamente

#### C. Usar Ejemplo
1. Haz clic en uno de los botones de ejemplo:
   - **Agente**: Script de matriz de transacciones para agentes
   - **Cajero**: Script de matriz de transacciones para cajeros
   - **Macrogiro**: Script de matriz de transacciones POS Macrogiro
2. El ejemplo se cargar√° pre-llenado

### Paso 2: Convertir

1. **Verifica tu script:**
   - Revisa que el c√≥digo est√© completo
   - Verifica el contador de l√≠neas (debe ser > 100 para scripts reales)

2. **Haz clic en "‚ö° Convertir a EDV"**
   - El proceso toma 1-2 segundos
   - Ver√°s un mensaje "‚è≥ Convirtiendo..."

3. **Espera los resultados:**
   - La secci√≥n de resultados aparecer√° autom√°ticamente
   - Se mostrar√° un scroll suave hacia los resultados

### Paso 3: Revisar Resultados

#### Tarjetas de Estad√≠sticas

Al completar la conversi√≥n ver√°s 4 m√©tricas:

1. **Cambios Aplicados**: N√∫mero de transformaciones realizadas
2. **Advertencias**: Alertas que requieren revisi√≥n manual
3. **Compliance Score**: Porcentaje de cumplimiento (0-100%)
4. **Estado**: PASS (‚â•80%) o FAIL (<80%)

#### Pesta√±as de Resultados

**üìä Diff**
- Vista lado a lado (ANTES | DESPU√âS)
- C√≥digo original DDV vs c√≥digo EDV generado
- L√≠neas modificadas resaltadas en verde
- Scroll sincronizado

**üìÑ Script EDV**
- C√≥digo completo generado
- Editor de solo lectura
- Botones: üìã Copiar | üíæ Descargar

**‚úÖ Checklist**
- Lista de validaciones con ‚úÖ o ‚ùå
- 11 checks de compliance:
  1. Widgets EDV
  2. Variables EDV
  3. Esquema de escritura EDV
  4. Destino EDV
  5. Tablas managed
  6. Optimizaciones Spark (8 configs)
  7. Repartition pre-escritura
  8. Columna de partici√≥n
  9. Sin rutas hardcodeadas
  10. Schema DDV usa views
  11. Limpieza con DROP TABLE

**üìù Log**
- Cambios aplicados detallados
- Advertencias (requieren atenci√≥n)
- Errores (deben corregirse)

### Paso 4: Descargar Script EDV

1. **Opci√≥n A: Copiar al Portapapeles**
   - Ve a la pesta√±a "üìÑ Script EDV"
   - Haz clic en "üìã Copiar"
   - Ver√°s confirmaci√≥n "‚úÖ Copiado"

2. **Opci√≥n B: Descargar Archivo**
   - Haz clic en "üíæ Descargar"
   - El archivo se descargar√° con nombre autom√°tico:
     - `MATRIZVARIABLES_HM_MATRIZTRANSACCIONAGENTE_EDV.py`
     - `MATRIZVARIABLES_HM_MATRIZTRANSACCIONCAJERO_EDV.py`
     - `HM_MATRIZTRANSACCIONPOSMACROGIRO_EDV.py`

## üîç Entendiendo los Cambios

### Cambios Autom√°ticos Aplicados

#### 1. Widgets EDV (Agregados)
```python
dbutils.widgets.text(name="PRM_CATALOG_NAME_EDV", defaultValue='catalog_lhcl_prod_bcp_expl')
dbutils.widgets.text(name="PRM_ESQUEMA_TABLA_EDV", defaultValue='bcp_edv_trdata_012')
```

#### 2. Variables EDV (Agregadas)
```python
PRM_CATALOG_NAME_EDV = dbutils.widgets.get("PRM_CATALOG_NAME_EDV")
PRM_ESQUEMA_TABLA_EDV = dbutils.widgets.get("PRM_ESQUEMA_TABLA_EDV")
PRM_ESQUEMA_TABLA_ESCRITURA = PRM_CATALOG_NAME_EDV + "." + PRM_ESQUEMA_TABLA_EDV
```

#### 3. Destino EDV (Modificado)
```python
# ANTES
VAL_DESTINO_NAME = PRM_ESQUEMA_TABLA + "." + PRM_TABLE_NAME

# DESPU√âS
VAL_DESTINO_NAME = PRM_ESQUEMA_TABLA_ESCRITURA + "." + PRM_TABLA_SEGUNDATRANSPUESTA
```

#### 4. Tablas Managed (Convertidas)
```python
# ANTES
df.write.format("delta").saveAsTable(tmp_table, path=ruta_salida)
df = spark.read.format("delta").load(ruta_salida)

# DESPU√âS
df.write.format("delta").saveAsTable(tmp_table)  # Sin path
df = spark.table(tmp_table)
```

#### 5. Optimizaciones Spark (Agregadas)
```python
spark.conf.set("spark.sql.adaptive.enabled", "true")
spark.conf.set("spark.sql.adaptive.coalescePartitions.enabled", "true")
spark.conf.set("spark.sql.adaptive.skewJoin.enabled", "true")
spark.conf.set("spark.sql.shuffle.partitions", "200")
spark.conf.set("spark.sql.autoBroadcastJoinThreshold", str(64*1024*1024))
spark.conf.set("spark.sql.sources.partitionOverwriteMode", "dynamic")
spark.conf.set("spark.databricks.delta.optimizeWrite.enabled", "true")
spark.conf.set("spark.databricks.delta.autoCompact.enabled", "true")
```

#### 6. Repartition Pre-Escritura (Agregado)
```python
input_df = input_df.repartition(CONS_PARTITION_DELTA_NAME)
write_delta(input_df, VAL_DESTINO_NAME, CONS_PARTITION_DELTA_NAME)
```

#### 7. Schema DDV con Views (Modificado)
```python
# ANTES
PRM_ESQUEMA_TABLA_DDV", defaultValue='bcp_ddv_matrizvariables'

# DESPU√âS
PRM_ESQUEMA_TABLA_DDV", defaultValue='bcp_ddv_matrizvariables_v'  # Agregado _v
```

#### 8. Limpieza de Temporales (Sugerido)
```python
# Se sugiere reemplazar
funciones.cleanPaths(...)

# Por
spark.sql(f"DROP TABLE IF EXISTS {tmp_table}")
```

## ‚ö†Ô∏è Advertencias Comunes

### 1. "cleanPaths detectado"
**Problema:** El script usa `funciones.cleanPaths()`

**Soluci√≥n:** Reemplazar manualmente con:
```python
spark.sql(f"DROP TABLE IF EXISTS {PRM_ESQUEMA_TABLA_ESCRITURA}.tabla_tmp")
```

### 2. "Verificar lecturas con spark.table()"
**Problema:** Las lecturas de temporales pueden estar incorrectas

**Soluci√≥n:** Asegurar que todas las lecturas de temporales usen:
```python
df = spark.table(f"{PRM_ESQUEMA_TABLA_ESCRITURA}.tabla_tmp")
```

### 3. "No se encontr√≥ secci√≥n de widgets"
**Problema:** El script no tiene estructura est√°ndar de widgets

**Soluci√≥n:** Agregar manualmente los widgets EDV al inicio del script

## ‚úÖ Checklist Pre-Deployment

Antes de ejecutar el script EDV en producci√≥n:

- [ ] Compliance Score ‚â• 80%
- [ ] Todas las advertencias revisadas
- [ ] Tablas temporales sin `path=`
- [ ] Lecturas usan `spark.table()`
- [ ] `DROP TABLE IF EXISTS` reemplaza `cleanPaths`
- [ ] Schema DDV termina en `_v` (views)
- [ ] Optimizaciones Spark presentes
- [ ] Repartition antes de write_delta
- [ ] Sin rutas hardcodeadas
- [ ] Prueba en ambiente de desarrollo primero

## ‚å®Ô∏è Atajos de Teclado

- **Ctrl + Enter**: Convertir script
- **Ctrl + S**: Descargar script EDV

## üêõ Soluci√≥n de Problemas

### El script no se carga
- Verifica que el archivo sea `.py`
- Aseg√∫rate de que no est√© corrupto
- Intenta copiar/pegar en vez de cargar archivo

### La conversi√≥n falla
- Revisa la consola del navegador (F12)
- Verifica que el script DDV sea v√°lido
- Reporta el issue en GitHub

### El diff no se muestra
- Refresca la p√°gina (F5)
- Limpia cache del navegador
- Intenta en otro navegador

### Score muy bajo (<80%)
- Revisa las advertencias en la pesta√±a Log
- Corrige manualmente los items marcados en rojo
- Vuelve a convertir despu√©s de correcciones

## üìû Soporte

- **Issues**: https://github.com/noctics123/generar_edv/issues
- **Documentaci√≥n**: [CLAUDE.md](../../CLAUDE.md)
- **Reglas de Conversi√≥n**: [REGLAS_CONVERSION.md](REGLAS_CONVERSION.md)

## üîÑ Actualizaciones

Para ver la √∫ltima versi√≥n:
```bash
git pull origin main
```

## üìù Contribuir

1. Fork el repo
2. Crea tu feature branch
3. Commit tus cambios
4. Push al branch
5. Abre un Pull Request

---

**√öltima actualizaci√≥n:** 2025-10-04
**Versi√≥n:** 1.0.0
