# EDV Converter - Web Application

AplicaciÃ³n web para convertir automÃ¡ticamente scripts de PySpark DDV a versiÃ³n EDV para BCP Analytics.

## ğŸ¯ DescripciÃ³n

Esta aplicaciÃ³n automatiza la conversiÃ³n de scripts de matriz de transacciones desde el ambiente DDV (Desarrollo) al ambiente EDV (ExploraciÃ³n/ProducciÃ³n), aplicando:

- âœ… SeparaciÃ³n de esquemas (lectura DDV, escritura EDV)
- âœ… ConversiÃ³n de tablas temporales a managed tables
- âœ… Optimizaciones de rendimiento (AQE, cache, repartition)
- âœ… ValidaciÃ³n automÃ¡tica de compliance
- âœ… GeneraciÃ³n de diff visual

## ğŸ“ Estructura del Proyecto

```
edv-converter-webapp/
â”œâ”€â”€ public/                      # Archivos estÃ¡ticos
â”‚   â”œâ”€â”€ index.html              # PÃ¡gina principal
â”‚   â”œâ”€â”€ favicon.ico
â”‚   â””â”€â”€ examples/               # Scripts de ejemplo
â”‚       â”œâ”€â”€ agente_ddv.py
â”‚       â”œâ”€â”€ cajero_ddv.py
â”‚       â””â”€â”€ macrogiro_ddv.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/             # Componentes UI
â”‚   â”‚   â”œâ”€â”€ FileUploader.js    # Carga de archivos
â”‚   â”‚   â”œâ”€â”€ DiffViewer.js      # VisualizaciÃ³n de diferencias
â”‚   â”‚   â”œâ”€â”€ ComplianceChecklist.js  # Checklist de validaciÃ³n
â”‚   â”‚   â””â”€â”€ DownloadButton.js  # Descarga de resultado
â”‚   â”œâ”€â”€ utils/                  # LÃ³gica de negocio
â”‚   â”‚   â”œâ”€â”€ edvConverter.js    # Motor de conversiÃ³n DDV->EDV
â”‚   â”‚   â”œâ”€â”€ validator.js       # Validador de compliance
â”‚   â”‚   â”œâ”€â”€ diffGenerator.js   # Generador de diff
â”‚   â”‚   â””â”€â”€ patterns.js        # Patrones regex de transformaciÃ³n
â”‚   â”œâ”€â”€ styles/                 # Estilos CSS
â”‚   â”‚   â”œâ”€â”€ main.css
â”‚   â”‚   â””â”€â”€ diff.css
â”‚   â””â”€â”€ app.js                  # AplicaciÃ³n principal
â”œâ”€â”€ docs/                       # DocumentaciÃ³n
â”‚   â”œâ”€â”€ GUIA_USO.md            # GuÃ­a de uso
â”‚   â”œâ”€â”€ REGLAS_CONVERSION.md   # Reglas de conversiÃ³n
â”‚   â””â”€â”€ API.md                 # API de componentes
â”œâ”€â”€ tests/                      # Tests
â”‚   â”œâ”€â”€ converter.test.js
â”‚   â””â”€â”€ validator.test.js
â”œâ”€â”€ examples/                   # Ejemplos completos
â”‚   â”œâ”€â”€ agente_antes_despues/
â”‚   â”œâ”€â”€ cajero_antes_despues/
â”‚   â””â”€â”€ macrogiro_antes_despues/
â”œâ”€â”€ package.json
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ CaracterÃ­sticas

### 1. ConversiÃ³n AutomÃ¡tica

Transforma scripts DDV a EDV aplicando:

- **Widgets EDV**: Agrega `PRM_CATALOG_NAME_EDV` y `PRM_ESQUEMA_TABLA_EDV`
- **Esquemas separados**: Lee de DDV (`bcp_ddv_matrizvariables_v`), escribe a EDV (`bcp_edv_trdata_012`)
- **Managed tables**: Convierte temporales de path a `saveAsTable()` sin path
- **Optimizaciones**: AQE, broadcast, repartition, Delta optimizeWrite
- **Limpieza**: Reemplaza `cleanPaths` por `DROP TABLE IF EXISTS`

### 2. ValidaciÃ³n de Compliance

Verifica automÃ¡ticamente:

- âœ… Widgets EDV presentes
- âœ… `PRM_ESQUEMA_TABLA_ESCRITURA` correctamente definido
- âœ… `VAL_DESTINO_NAME` apunta a EDV
- âœ… Temporales sin `path=`
- âœ… Lecturas con `spark.table()`
- âœ… Configuraciones Spark AQE
- âœ… Repartition antes de write_delta
- âœ… ParticiÃ³n correcta (CODMES vs codmes)

### 3. Diff Interactivo

- Vista lado a lado (antes/despuÃ©s)
- Resaltado de cambios
- NavegaciÃ³n por secciones modificadas
- ExportaciÃ³n de diff en Markdown

### 4. Ejemplos Incluidos

Scripts de referencia:
- Agente (DDV â†’ EDV)
- Cajero (DDV â†’ EDV)
- Macrogiro (DDV â†’ EDV)

## ğŸ› ï¸ TecnologÃ­as

- **Frontend**: HTML5, CSS3, JavaScript (Vanilla)
- **Diff Engine**: diff-match-patch
- **Syntax Highlighting**: Prism.js
- **Deployment**: GitHub Pages (estÃ¡tico)

## ğŸ“– Uso

### OpciÃ³n 1: Cargar Archivo

1. Hacer clic en "Cargar Script DDV"
2. Seleccionar archivo `.py`
3. Hacer clic en "Convertir a EDV"
4. Revisar diff y checklist
5. Descargar script EDV

### OpciÃ³n 2: Pegar CÃ³digo

1. Pegar cÃ³digo en el editor
2. Hacer clic en "Convertir a EDV"
3. Revisar cambios
4. Copiar o descargar resultado

### OpciÃ³n 3: Usar Ejemplo

1. Seleccionar ejemplo (Agente/Cajero/Macrogiro)
2. Ver conversiÃ³n pre-calculada
3. Estudiar patrones aplicados

## ğŸ” Reglas de TransformaciÃ³n

### 1. Widgets EDV

```python
# AGREGADO
dbutils.widgets.text(name="PRM_CATALOG_NAME_EDV", defaultValue='catalog_lhcl_prod_bcp_expl')
dbutils.widgets.text(name="PRM_ESQUEMA_TABLA_EDV", defaultValue='bcp_edv_trdata_012')

PRM_CATALOG_NAME_EDV = dbutils.widgets.get("PRM_CATALOG_NAME_EDV")
PRM_ESQUEMA_TABLA_EDV = dbutils.widgets.get("PRM_ESQUEMA_TABLA_EDV")
```

### 2. Esquema de Escritura

```python
# AGREGADO
PRM_ESQUEMA_TABLA_ESCRITURA = PRM_CATALOG_NAME_EDV + "." + PRM_ESQUEMA_TABLA_EDV

# MODIFICADO
VAL_DESTINO_NAME = PRM_ESQUEMA_TABLA_ESCRITURA + "." + PRM_TABLA_SEGUNDATRANSPUESTA
```

### 3. Temporales Managed

```python
# ANTES
df.write.format("delta").saveAsTable(tmp_table, path=ruta_salida)
df = spark.read.format("delta").load(ruta_salida)

# DESPUÃ‰S
df.write.format("delta").saveAsTable(tmp_table)  # Sin path
df = spark.table(tmp_table)
```

### 4. Optimizaciones Spark

```python
# AGREGADO al inicio
spark.conf.set("spark.sql.adaptive.enabled", "true")
spark.conf.set("spark.sql.adaptive.coalescePartitions.enabled", "true")
spark.conf.set("spark.sql.adaptive.skewJoin.enabled", "true")
spark.conf.set("spark.sql.shuffle.partitions", "200")
spark.conf.set("spark.sql.autoBroadcastJoinThreshold", str(64*1024*1024))
spark.conf.set("spark.sql.sources.partitionOverwriteMode", "dynamic")
spark.conf.set("spark.databricks.delta.optimizeWrite.enabled", "true")
spark.conf.set("spark.databricks.delta.autoCompact.enabled", "true")
```

### 5. Repartition Pre-Escritura

```python
# AGREGADO antes de write_delta
input_df = input_df.repartition(CONS_PARTITION_DELTA_NAME)
write_delta(input_df, VAL_DESTINO_NAME, CONS_PARTITION_DELTA_NAME)
```

## ğŸ§ª Testing

```bash
# Ejecutar tests
npm test

# Coverage
npm run coverage
```

## ğŸ“¦ Deployment

### GitHub Pages

```bash
# Build
npm run build

# Deploy
npm run deploy
```

La app estarÃ¡ disponible en: `https://noctics123.github.io/generar_edv/`

## ğŸ¤ Contribuir

1. Fork el repositorio
2. Crear branch de feature (`git checkout -b feature/nueva-regla`)
3. Commit cambios (`git commit -m 'Agregar nueva regla de conversiÃ³n'`)
4. Push al branch (`git push origin feature/nueva-regla`)
5. Abrir Pull Request

## ğŸ“ Checklist de ConversiÃ³n EDV

- [ ] Widgets EDV agregados
- [ ] `PRM_ESQUEMA_TABLA_ESCRITURA` definido
- [ ] `VAL_DESTINO_NAME` apunta a EDV
- [ ] Temporales son managed tables (sin `path=`)
- [ ] Lecturas con `spark.table()`
- [ ] Configuraciones Spark AQE aplicadas
- [ ] Repartition antes de write
- [ ] ParticiÃ³n correcta
- [ ] `DROP TABLE IF EXISTS` para temporales
- [ ] Sin rutas hardcodeadas

## ğŸ“š DocumentaciÃ³n Adicional

- [GuÃ­a de ConversiÃ³n Completa](docs/GUIA_USO.md)
- [Reglas de TransformaciÃ³n](docs/REGLAS_CONVERSION.md)
- [API de Componentes](docs/API.md)
- [Ejemplos Paso a Paso](examples/)

## ğŸ› Problemas Conocidos

- Los scripts muy grandes (>10MB) pueden tardar en procesarse
- Algunos patrones complejos de SQL embebido requieren revisiÃ³n manual

## ğŸ“„ Licencia

MIT

## ğŸ‘¥ Autores

- BCP Analytics Team
- Generado con Claude Code

## ğŸ”— Enlaces

- [Repositorio](https://github.com/noctics123/generar_edv)
- [Issues](https://github.com/noctics123/generar_edv/issues)
- [DocumentaciÃ³n BCP](CLAUDE.md)

---

**Ãšltima actualizaciÃ³n:** 2025-10-04
